{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next word prediction using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw6eEOtElmJl"
      },
      "source": [
        "## **Building a Neural network to predict the next word given a part of sentence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8doDgl5BKkS-"
      },
      "source": [
        "Importing important libraries for this Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6prUz0etFjxo"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvg11ZenHhPf"
      },
      "source": [
        "Uploading the text file to make our prediction model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "d-Hyq6-0F0Q2",
        "outputId": "e0cdf14a-19f5-4b46-f7d0-c105a7da0d1a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_file = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c7bc4cc-2ef2-4f95-a533-24dff5449600\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c7bc4cc-2ef2-4f95-a533-24dff5449600\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving The Adventures of Sherlock Holmes.txt to The Adventures of Sherlock Holmes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qx-7atmH1LP"
      },
      "source": [
        "Loading and preprocessing of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCmTJ4NGHWBo"
      },
      "source": [
        "file = open('The Adventures of Sherlock Holmes.txt', 'r', encoding = 'utf8')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lkHcwmhIdzG"
      },
      "source": [
        "Storing the file in a list and converting the list into string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtlgDSW1ObYc"
      },
      "source": [
        "lines = []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEg9W3DNHV-2"
      },
      "source": [
        "\n",
        "for line in file:\n",
        "  lines.append(line)\n",
        "\n",
        "# Converting list into string\n",
        "dataset = ''\n",
        "for line in lines:\n",
        "  dataset = ' '.join(lines) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2jHwiiyN8SL",
        "outputId": "bc7c4f5b-88e0-4ebc-945e-a48a56e0374d"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12310"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4pOfFceN7pz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zLcXnNIK2xN"
      },
      "source": [
        "Removing unnecessary characters from our dataset like - \", ', lines, carriage return, unicode characters etc.\n",
        "\n",
        "We will replace all these characters with spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1niPsiWHV7-"
      },
      "source": [
        "dataset = dataset.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('\"', '')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxVeFNdTNEXE"
      },
      "source": [
        "Removing unnecessary spaces from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "p3congjeHV5G",
        "outputId": "b688897a-bdf1-4bb7-a847-0ae13dd3f633"
      },
      "source": [
        "dataset = dataset.split()\n",
        "dataset = ' '.join(dataset)\n",
        "dataset[:1000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: The Adventures of Sherlock Holmes Author: Arthur Conan Doyle Release Date: November 29, 2002 [EBook #1661] Last Updated: May 20, 2019 Language: English Character set encoding: UTF-8 *** START OF THIS PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES *** Produced by an anonymous Project Gutenberg volunteer and Jose Menendez cover The Adventures of Sherlock Holmes by Arthur Conan Doyle Contents I. A Scandal in Bohemia II. The Red-Headed League III. A Case of Identity IV. The Boscombe Valley Mystery V. The Five Orange Pips VI. The Man with the Twisted Lip VII. The Adventure of the Blue Carbuncle VIII. The Adventure of the Speckled Band IX. The Adventure o\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B37ZVXeHV2n",
        "outputId": "6da83536-5989-4534-c76f-ad18c92aac51"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "578728"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl2D9crTknXW",
        "outputId": "3f437944-8513-4df2-b2be-365c94bf24aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azi5vNlSR1iR"
      },
      "source": [
        "Using tokenizer to convert text to sequence and sequence to text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCp66HcXHVz-",
        "outputId": "a04f8afb-a973-4e21-b5ea-947bf0fb7dff"
      },
      "source": [
        "tokenizer = Tokenizer()   # creating an object of tokenizer\n",
        "tokenizer.fit_on_texts([dataset])  # passing the preprocessed data\n",
        "\n",
        "pickle.dump(tokenizer, open(F\"/content/drive/My Drive/Neural_Network/token.pkl\", 'wb'))  # saving the tokenizer file\n",
        "\n",
        "sequence_dataset = tokenizer.texts_to_sequences([dataset])[0]   # converting our string into numeric representation\n",
        "sequence_dataset[:15]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[145, 4789, 1, 1020, 4, 128, 34, 45, 611, 2235, 2236, 30, 1021, 15, 23]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI9bIpb8HVxf",
        "outputId": "8263d6c5-14a5-4c29-a5d8-084d8d65dbbe"
      },
      "source": [
        "len(sequence_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111252"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ZgVdLivWKA"
      },
      "source": [
        "The number of sequence characters are less than the number of characters in the dataset. This means that there some words that are repeated in the dataset. Each unique word is given a sequence or number which can then be used for further processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87EzktTuHVu-",
        "outputId": "6cc0be9b-165c-4034-9a8e-760cf28c414e"
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "print(vocabulary_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibAJEjbdnC6P"
      },
      "source": [
        "We have 8931 unique words in our text corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZe_p0Ddrdkd"
      },
      "source": [
        "We will use 4 words to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W-EMFVSHVsY"
      },
      "source": [
        "sequences = []"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "METlnpUqzZGU"
      },
      "source": [
        "for i in range(4, len(sequence_dataset)):\n",
        "  words = sequence_dataset[i-4:i+1]\n",
        "  sequences.append(words)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTcseD-XzZDc",
        "outputId": "22269f7b-1b93-4cf9-dbb3-2ad226de6f43"
      },
      "source": [
        "print('The length of sequences list :', len(sequences))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of sequences list : 111248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OT1rjJt0xjO"
      },
      "source": [
        "Converting the list into an nd array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEYCrIEuzZAj",
        "outputId": "8fc00430-7391-434b-8f38-bc7aed2b25d6"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 145, 4789,    1, 1020,    4],\n",
              "       [4789,    1, 1020,    4,  128],\n",
              "       [   1, 1020,    4,  128,   34],\n",
              "       [1020,    4,  128,   34,   45],\n",
              "       [   4,  128,   34,   45,  611],\n",
              "       [ 128,   34,   45,  611, 2235],\n",
              "       [  34,   45,  611, 2235, 2236],\n",
              "       [  45,  611, 2235, 2236,   30],\n",
              "       [ 611, 2235, 2236,   30, 1021],\n",
              "       [2235, 2236,   30, 1021,   15]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n1co_b21Eqk"
      },
      "source": [
        "Now, the first four digits in our sequences array (for each row) are our four features/ independent variables and the fifth digit is the dependent variable/ output variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNdfC0Uq3fTi"
      },
      "source": [
        "Let's separate our input and output variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rHkuofkzY-E"
      },
      "source": [
        " x = []\n",
        " y = []\n",
        "\n",
        " for i in sequences:\n",
        "   x.append(i[0:4])\n",
        "   y.append(i[4])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYB6AQR7362j"
      },
      "source": [
        "Converting the list into np arrays so that matrix calculation can then easily be carried out on our dependent and independent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvrvCtLjzY7X"
      },
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9WCRsKT4QZ0",
        "outputId": "8e4f5992-df74-46e4-eab0-08c3aee0ae2b"
      },
      "source": [
        "print('Input features: ', x[:5], '\\n')\n",
        "print('Output Label : ', y[:5])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input features:  [[ 145 4789    1 1020]\n",
            " [4789    1 1020    4]\n",
            " [   1 1020    4  128]\n",
            " [1020    4  128   34]\n",
            " [   4  128   34   45]] \n",
            "\n",
            "Output Label :  [  4 128  34  45 611]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOhktDhW7y2o"
      },
      "source": [
        "We have to convert our output class vector into some binary class matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmx1Mf06DFVs",
        "outputId": "a8ee18f5-7632-49d5-93f9-8a273936d412"
      },
      "source": [
        "y = to_categorical(y, num_classes = vocabulary_size)\n",
        "y[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_BNKd5FDZCN"
      },
      "source": [
        "Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utrqgy7P4TRy"
      },
      "source": [
        "# Sequential is used to create our deep learning model.\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer that takes 3 arguments: input dimension, output dimension, input length. \n",
        "model.add(Embedding(vocabulary_size, 10, input_length = 4))\n",
        "\n",
        "# LSTM layer having two parameters: Dimensionality of the output space, return_sequence = True indicated that next LSTM layer will be created.\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "\n",
        "# Second LSTM layer\n",
        "model.add(LSTM(1000))\n",
        "\n",
        "# Dense layer with units and activation function as arguments.\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "\n",
        "# output layer.\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFm7Ys-f93Py",
        "outputId": "9f450eba-551a-4b87-c5b5-ad6a1439cb15"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 4, 10)             89310     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 4, 1000)           4044000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8931)              8939931   \n",
            "=================================================================\n",
            "Total params: 22,078,241\n",
            "Trainable params: 22,078,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU_vQQdUHVDw"
      },
      "source": [
        "Schematic of our Neural Network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "vpt60FIN94JY",
        "outputId": "39faa321-d74e-495b-ad2e-b68b2405e6e7"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model, to_file = 'plot.png', show_layer_names = True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAIjCAYAAAD/dYWXAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dfVhT990/8PdJCCRBEhEQanlQaBWfnVaLFK3V29527VwrqKj40M1N69VZ16q01TnvTtZ2amHrtL2s3l3ve/0hKJ1Op15u1aKr2qq1alV8rFqHCFUEJQgBPr8/OnIvgy8GgSSa9+u68gfffHO+n5Nz8uY8JOdoIiIgImqEztMFEJH3YkAQkRIDgoiUGBBEpOT37w179+7FW2+95YlaiMiDXnzxRQwePNiprcEWxDfffIP169e7rSgi8rz169fjm2++adDeYAui3rp169q0ICLyHpqmNdrOYxBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUvLqgBg4cCD0ej369evX6tOePn06goKCoGkavvzyy2b327JlC6xWKzZt2tTqtTWXN9Vyp/bt24fu3btDp9NB0zSEh4djyZIlni7LSV5eHmJjY6FpGjRNQ0REBNLS0jxdVpvy6oDYv38/HnvssTaZ9urVq/Hee+/dcT9vuluAN9VypxISEnDixAk8/vjjAICTJ09i4cKFHq7KWXJyMs6dO4e4uDhYrVYUFRXhj3/8o6fLalPKC8Z4E9XFLDzpySefRFlZmafLAOBdtVRWVmLEiBHYs2ePp0tpsXtpXu6UV29B1DMYDG0yXVeDxx0BJSJYt24dVq1a1eZjtaU1a9aguLjY02W0intpXu6Y/JucnBxppLlJNTU18otf/EKioqLEaDRK7969Ze3atSIikpmZKWazWTRNk/79+0vHjh3Fz89PzGazfO9735OkpCSJjIyUgIAAsVqtMm/ePKdpjxgxQoKDg6Vbt25iNpvFaDRKUlKS7N692+UaRETq6urkN7/5jXTt2lX8/f3FYrFIVFSUAJBDhw41q9/u3bsdbW+//baIiKxYsULMZrOYTCbZsGGDjBo1SoKCguT++++X//f//l+DWjMyMqRr165iNBolJCREYmJipF+/flJaWtqs974ltfz2t7+VgIAACQsLkxkzZkhERIQEBATI4MGDZd++fY5+P/vZz8RgMEh4eLijbdasWWI2mwWAlJSUiIjICy+8IP7+/gJAAEhcXJyIiGzdulWCgoJkyZIlt52f//zP/xQAjvfB2+ZFRCQuLk6sVqsLS0dk165d0r17d7FYLBIQECC9evWSbdu2iYjIj3/8Y8f0Y2Nj5YsvvhARkWnTponJZBKLxSIbN24UkabX7zfffFNMJpO0a9dOrly5Ii+++KJ06tRJCgoKXKpRRASA5OTkNGz/94Y7CYi5c+dKQECArF+/XkpLS+XVV18VnU4n+/fvFxGRX/7ylwJAPvvsM6moqJBvv/1WRo0aJQDkL3/5i5SUlEhFRYXMnj1bAMiXX37pmPaIESMkNjZWvv76a7Hb7fLVV1/Jww8/LEajUU6dOuVyDQsWLBBN02T58uVSWloqNptNVqxY0SAgXO33zTffOH0o618LQD7++GMpKyuT4uJiGTJkiAQGBkp1dbWjX0ZGhuj1etm4caPYbDY5ePCghIeHy7Bhw5r1vrdGLTNmzJDAwEA5fvy43Lp1S44dOyYDBw6UoKAguXjxoqPfpEmTnD5UIiJLly51+lCJiCQnJzt9mERENm/eLEFBQfLaa6/ddl7+PSC8bV5EmhcQ69atk8WLF8u1a9fk6tWrkpCQICEhIU5j6PV6+cc//uH0uokTJ8qf//xnx9+urN8A5IUXXpC3335bxowZIydOnHCpRpE2DIjKykoxm82SmprqaLPZbBIQECCzZs0Skf8LiBs3bjj6fPDBBwJAjh496mj7/PPPBYDTf/4RI0ZI3759ncY8cuSIAJC5c+e6VIPNZhOz2SwjR450mk52drbTB9/VfiJNfygrKysdbfXhcubMGUfbwIEDZdCgQU5j/PSnPxWdTidVVVXSXC2pZcaMGQ1W9v379wsA+a//+i9HW0s/VK5qKiC8ZV6aExD/7te//rUAkOLiYhER+dvf/iYAnLauysrK5MEHH5SamhoRce0z1th71ByqgGjxMYiTJ0/CZrOhV69ejjaTyYSIiAgUFBQoX+fv7w8AqKmpcbTVH2uw2+1Njtm7d29YrVYcOXLEpRrOnDkDm82GESNGNDldV/s1R/18/us83bp1q8GZh9raWhgMBuj1+lYb25VaGvPQQw/BbDY3ufw87W6dl/p1vLa2FgAwfPhwdO3aFf/93//tWCfWrl2L1NRUx7pwp5+x1tDigKioqAAALFy40HF+WNM0XLhwATabrcUFqhgMBsfKcbsaLl26BAAICwtrcpqu9mup73//+zh48CA2btyIyspKHDhwABs2bMBTTz3VpgHRHAEBASgpKfF0Ga3Ck/Pyl7/8BcOGDUNYWBgCAgIwf/58p+c1TcPMmTNx7tw5fPzxxwCA//mf/8GPf/xjRx9PfcaAVgiI+g9TZmYm5LtdFsdj7969LS6wMTU1Nbh27Rqio6NdqsFoNAIAqqqqmpyuq/1aavHixRg+fDimTZsGi8WCMWPGYNy4cS59L8Md7HY7rl+/jsjISE+X0mLunpddu3YhMzMTAHDx4kU888wziIiIwGeffYaysjK8+eabDV4zbdo0GI1GrF69GidPnoTFYkFMTIzjeU98xuq1+HsQUVFRMBqNTX4bsbXt3LkTdXV16N+/v0s19OrVCzqdDvn5+XjuueeU03W1X0sdO3YMZ8+eRUlJCfz8vO+rKJ988glEBAkJCY42Pz+/227OeyN3z8vBgwcRGBgIADh69CjsdjtmzZqF2NhYAI2fMg8ODsb48eOxdu1aBAUF4Sc/+YnT8574jNVr8RaE0WjEs88+i+zsbKxcuRLl5eWora3FpUuXcPny5daoEdXV1SgrK0NNTQ2++OILzJ49GzExMZg2bZpLNYSFhSE5ORnr16/HmjVrUF5ejiNHjjT4zoGr/Vrq+eefR3R0NG7evNmq071TdXV1KC0tRU1NDY4cOYI5c+YgOjra8f4CwAMPPIBr165hw4YNsNvtKCkpwYULFxpMq0OHDigsLMT58+dx48YN2O12bN26FRaLBRkZGXf9vKjY7XZcuXIFn3zyiSMg6rdw//a3v+HWrVs4ffo0Pvvss0Zf/9xzz6GqqgqbN2/GD37wA6fn3PEZU/r3o5Z3cpqzqqpK0tPTJTo6Wvz8/CQsLEySk5Pl2LFjkpWV5TjH3LlzZ9m9e7e88cYbYrVaBYCEh4fLhx9+KGvXrpXw8HABIMHBwZKdnS0iIu+//7489thjju9PhISEyIQJE+TChQsu1yAicuPGDZk+fbqEhIRIu3btJCkpSRYtWiQAJDIyUg4fPuxyv7ffflsiIiIEgJjNZhk9erTjfD0AefDBB+Xs2bOyatUqsVgsAkBiYmIcp2V37NghISEhjnPgAMRgMEj37t0lLy+vWe99S2uZMWOGGAwGuf/++8XPz08sFos8/fTTcvbsWadxrl69Ko899pgYjUbp0qWL/OxnP5N58+YJAHnggQccpxG/+OILiYmJEZPJJElJSVJUVCRbtmy57fcg9u3bJz179hSdTicAJCIiQjIyMrxqXt555x2Ji4tzWm6NPT766CPHWOnp6dKhQwdp3769jB07Vn7/+987vlfxr6deRUS+973vySuvvNLo+9PU+l3/PQgAEhUVJf/7v//ryqrjBG35PQhqnhUrVsicOXOc2qqqquTnP/+5BAQEiM1mc1stM2bMkA4dOrhtvLZ0t8/L97//fTl37pxHxlYFhPftAN/jioqKMHv27Ab7k/7+/oiOjobdbofdbofJZHJbTfWn3O4Fd9O82O12x2nPI0eOwGg0okuXLh6uytld8VuMe4nJZILBYMCaNWtw5coV2O12FBYWYvXq1Vi0aBFSU1NRWFjodDpL9UhNTfX07FALpKen4/Tp0zh16hSeffZZ/OpXv/J0SQ39+yYFdzHa3q5du+Q//uM/xGKxiF6vF6vVKomJibJixQqx2+1uq+OVV15x/N6gc+fOsm7dOreN3druxnlZsGCB6HQ6iYqKcvpatSdAsYuh/fNJh9zcXIwfP/6euMYAEblG0zTk5ORg3LhxTu3cxSAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJSXjBm7Nix7qyDiLxQgy2IqKgopKSkeKIW8rADBw7gwIEDni6DPCAlJQVRUVEN2htcD4J8V/21AHJzcz1cCXkLHoMgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJU1ExNNFkPv94Q9/QFZWFmprax1tJSUlAICwsDBHm16vx5w5czBt2jR3l0hegAHho06ePIn4+HiX+p44ccLlvnRv4S6Gj+rWrRt69+4NTdOUfTRNQ+/evRkOPowB4cOmTJkCvV6vfN7Pzw9Tp051Y0XkbbiL4cMKCwsRGRkJ1SqgaRouXryIyMhIN1dG3oJbED6sU6dOSExMhE7XcDXQ6XRITExkOPg4BoSPmzx5cqPHITRNw5QpUzxQEXkT7mL4uGvXriE8PBw1NTVO7Xq9HleuXEFISIiHKiNvwC0IH9ehQweMHDkSfn5+jja9Xo+RI0cyHIgBQUBaWhrq6uocf4sIJk+e7MGKyFtwF4NQUVGB0NBQ3Lp1CwAQEBCAb7/9Fu3atfNwZeRp3IIgBAYGYvTo0TAYDPDz88PTTz/NcCAADAj6p0mTJqGmpga1tbWYOHGip8shL+F3+y6tZ+/evfjmm2/cOSS5qLa2FkajESKCmzdvIjc319MlUSOioqIwePBg9w0obpSSkiIA+OCDjzt8pKSkuPMjK27dggCAlJQUrFu3zt3Dkgt27twJTdMwbNgwT5dCjRg7dqzbx3R7QJD3evTRRz1dAnkZBgQ5NPabDPJtXCOISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkZLPBsTAgQOh1+vRr1+/Vp/29OnTERQUBE3T8OWXXza735YtW2C1WrFp06ZWr6058vLyEBsbC03TlI/OnTu3ylhcHt7JZwNi//79eOyxx9pk2qtXr8Z77713x/3ES64jnJycjHPnziEuLg5WqxUiAhFBTU0NbDYbrly5ArPZ3CpjcXl4J5//uXdTd7f2lCeffBJlZWWeLkNJr9fDZDLBZDKha9eurTptLg/v4rNbEPUMBkObTNfVFd0dHwgRwbp167Bq1apWn/aGDRtadXpcHt7F6wOitrYWixYtQnR0NEwmE/r06YOcnBwAQFZWFgIDA6HT6TBgwACEh4fDYDAgMDAQ/fv3x5AhQxAVFQWj0Yj27dtj/vz5DaZ/5swZxMfHIzAwECaTCUOGDMHf//53l2sAvlvgS5cuRbdu3RAQEACr1Yp58+Y1GMuVfn//+98RHR0NTdPw+9//HgCwcuVKBAYGwmw2Y+PGjXjiiSdgsVgQGRmJ7OzsBrX++te/Rrdu3WAymRAaGoouXbrg17/+NcaNG+fot23bNlgsFmRkZDRziahxedz58vBa7rwAZkpKSrMvujl37lwJCAiQ9evXS2lpqbz66qui0+lk//79IiLyy1/+UgDIZ599JhUVFfLtt9/KqFGjBID85S9/kZKSEqmoqJDZs2cLAPnyyy8d0x4xYoTExsbK119/LXa7Xb766it5+OGHxWg0yqlTp1yuYcGCBaJpmixfvlxKS0vFZrPJihUrBIAcOnTIMR1X+33zzTcCQN5++22n1wKQjz/+WMrKyqS4uFiGDBkigYGBUl1d7eiXkZEher1eNm7cKDabTQ4ePCjh4eEybNgwp/d18+bNEhQUJK+99tptl0FcXJxYrVanthdeeEGOHj3aoC+Xx50tD1fcyeenpbw6ICorK8VsNktqaqqjzWazSUBAgMyaNUtE/m+FvHHjhqPPBx98IACcVuDPP/9cAMjatWsdbSNGjJC+ffs6jXnkyBEBIHPnznWpBpvNJmazWUaOHOk0nezsbKcVzdV+Ik2vkJWVlY62+pX5zJkzjraBAwfKoEGDnMb46U9/KjqdTqqqquROxMXFNXqF5aYCgsvjO625PDwREF69i3Hy5EnYbDb06tXL0WYymRAREYGCggLl6/z9/QHA6Y7V9fu2dru9yTF79+4Nq9WKI0eOuFTDmTNnYLPZMGLEiCan62q/5qifz3+dp1u3bjU46l5bWwuDwQC9Xn/HY/3rWQwRwQsvvNDsOrk8vtMay8NdvDogKioqAAALFy50Ovd+4cIF2Gy2NhvXYDA4FvLtarh06RIAICwsrMlputqvpb7//e/j4MGD2LhxIyorK3HgwAFs2LABTz31VKuukFlZWU4f0rbE5eE5Xh0Q9QsvMzPT6b+XiGDv3r1tMmZNTQ2uXbuG6Ohol2owGo0AgKqqqian62q/llq8eDGGDx+OadOmwWKxYMyYMRg3bpxL3wPwRlwenuXVAVF/xLupb7+1tp07d6Kurg79+/d3qYZevXpBp9MhPz+/yem62q+ljh07hrNnz6KkpAR2ux0XL17EypUrERwc3CbjXb58Gc8++2ybTBvg8vA0rw4Io9GIZ599FtnZ2Vi5ciXKy8tRW1uLS5cu4fLly60yRnV1NcrKylBTU4MvvvgCs2fPRkxMDKZNm+ZSDWFhYUhOTsb69euxZs0alJeX48iRIw3Ocbvar6Wef/55REdH4+bNm03227p1a4tOc4oIKisrkZeXB4vFckfTaIyvLg+v5c4jondyFLaqqkrS09MlOjpa/Pz8JCwsTJKTk+XYsWOSlZUlZrNZAEjnzp1l9+7d8sYbb4jVahUAEh4eLh9++KGsXbtWwsPDBYAEBwdLdna2iIi8//778thjj0nHjh3Fz89PQkJCZMKECXLhwgWXaxARuXHjhkyfPl1CQkKkXbt2kpSUJIsWLRIAEhkZKYcPH3a539tvvy0RERECQMxms4wePVpWrFjhmM8HH3xQzp49K6tWrRKLxSIAJCYmxnEacMeOHRISEuJ0tsFgMEj37t0lLy/PMU9btmyRoKAgWbJkifK9/+ijj5RnMP71sXDhQhERLo8WLA9XeOIshibivi+a199bkPfmbDsrV67E6dOnkZmZ6Wirrq7Gyy+/jJUrV6K0tBQmk8mDFfqW1lwenvj8+PxvMe4lRUVFmD17doP9c39/f0RHR8Nut8NutzMg3OReWB5efQyCmsdkMsFgMGDNmjW4cuUK7HY7CgsLsXr1aixatAipqamteryAmnYvLA8GxD3EarVi+/bt+Oqrr9C1a1eYTCb06NED77//Pt544w188MEHni7Rp9wLy4O7GPeYIUOG4K9//auny6B/utuXB7cgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlNz+a85Lly4hNzfX3cMS3fUuXbqEyMhIt47p9oDYt28fxo8f7+5hie4JKSkpbh3PrdekJO9WfzNZbuFRPR6DICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiU/TxdAnpGfn499+/Y5tRUUFAAA3nzzTaf2hIQEPProo26rjbyHJiLi6SLI/f7617/i8ccfh8FggE7X+IZkXV0d7HY7tm/fjpEjR7q5QvIGDAgfVVtbi/DwcFy9erXJfsHBwSguLoafHzc2fRGPQfgovV6PSZMmwd/fX9nH398fkydPZjj4MAaED5swYQKqq6uVz1dXV2PChAlurIi8DXcxfFxMTAwuXrzY6HORkZG4ePEiNE1zc1XkLbgF4ePS0tJgMBgatPv7+2Pq1KkMBx/HLQgfd+LECfTo0aPR544ePYpevXq5uSLyJgwIQo8ePXDixAmntvj4+AZt5Hu4i0GYMmWK026GwWDA1KlTPVgReQtuQRAuXryIzp07o35V0DQN586dQ+fOnT1bGHkctyAI0dHReOihh6DT6aBpGgYOHMhwIAAMCPqnKVOmQKfTQa/XY/LkyZ4uh7wEdzEIAFBSUoL77rsPAPCPf/wD4eHhHq6IvAG3IFwwduxYaJp2Tz86duyI2tpa1NbWIiIiwuP1tPVj7Nixnl6t7gr8kr2LEhIS8POf/9zTZbSp/Px8aJqGoUOHerqUNpWZmenpEu4aDAgXRUZGYty4cZ4uo02NGjUKAGCxWDxcSdtat26dp0u4azAgyOFeDwZqPh6DICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAtIFly5ahY8eO0DQN7777rqfLUcrLy0NsbKzjIioRERFIS0u77esOHz6M1NRUdOnSBQEBAQgNDUXfvn2xZMkSR5/U1FSXL96yefPmBrX84he/aLKGt956C5qmQafTIT4+Hrt27Wrx+0ENMSDawNy5c7Fnzx5Pl3FbycnJOHfuHOLi4mC1WlFUVIQ//vGPTb7m6NGjSExMREREBHbu3ImysjLs2bMHo0aNwieffOLUd/v27bh+/TrsdjsuX74MABg9ejSqq6tRUVGB4uJi/OQnP2lQCwCsXr0adru90Rpqa2vxu9/9DgAwfPhwFBQU3PMXufEUBoSXqKysRGJioqfLuK1ly5ahffv2yMrKQufOnWE0GtG1a1f86le/gslkcvTTNA2PPPIIrFar093BNU2DwWCA2WxGWFgYBgwY0GCMAQMGoKioCBs2bGi0hry8PNx///2tP3PUAAPCS6xZswbFxcWeLuO2rl69irKyMly7ds2p3d/fH5s2bXL8nZ2dDbPZfNvpzZgxA0899ZRT26xZswAA77zzTqOveeutt/DSSy81t3S6AwwIN8rPz8egQYNgNpthsVjQu3dvlJeXY86cOXjppZdw9uxZaJqGBx54AFlZWQgMDIROp8OAAQMQHh4Og8GAwMBA9O/fH0OGDEFUVBSMRiPat2+P+fPnO421bds2WCwWZGRktOo8DBw4EBUVFRg+fDg+/fTTVp12veHDh6N79+7YuXMnTp486fTcp59+CpvNhscff7xNxiZnDAg3qaiowOjRo5GSkoJr167h9OnT6Nq1K6qrq5GVlYUf/OAHiIuLg4jgzJkzmDNnDubNmwcRwTvvvIOvv/4aRUVFGDp0KA4dOoRXXnkFhw4dwrVr1zB16lQsXboUhw8fdoxXW1sLAKirq2vV+Zg/fz4eeughHD58GElJSejZsyd+85vfNNiiaKmZM2cCQIODvMuXL8eLL77YqmORGgPCTc6fP4/y8nL07NkTRqMR4eHhyMvLQ2ho6G1f26NHD5jNZoSEhGDChAkAvrsbVmhoKMxms+PMQ0FBgeM1Tz75JMrLy297NqC5TCYT9uzZg9/+9reIj4/H8ePHkZ6eju7duyM/P7/Vxpk6dSoCAwPxwQcfoLKyEgBw7tw57N+/HxMnTmy1cahpDAg3iY2NRceOHZGWlobFixfj/PnzdzQdf39/AEBNTY2jrf7Gu6qj/q3NYDBg9uzZOHHiBPbt24enn34axcXFGDt2LEpLS1tlDKvViokTJ6K0tBRr164F8N3l6mfNmuV4D6jtMSDcxGQyYceOHUhKSkJGRgZiY2ORmprq+O94t3r44Yfxpz/9Cc899xxKSkqwc+fOVpt2/cHKd999F9evX8e6descux7kHgwIN+rZsyc2bdqEwsJCpKenIycnB8uWLfN0WU3atWuX041mkpOTnbZe6tXfz9Nms7Xa2P369UNCQgI+//xzzJgxA2PHjkVwcHCrTZ9ujwHhJoWFhTh+/DgAICwsDK+//jr69+/vaPNWBw8eRGBgoOPvqqqqRmuuP9vQp0+fVh2/fiti/fr19/ydzbwRA8JNCgsLMXPmTBQUFKC6uhqHDh3ChQsXkJCQAADo0KEDCgsLcf78edy4caPFxxO2bt3aotOcdrsdV65cwSeffOIUEADwzDPPIDc3F9evX0dZWRk2btyIl19+GT/84Q9bPSDGjRuH0NBQPPPMM4iNjW3VaZMLhG4rJSVFUlJSXO6/fPlyCQ8PFwASGBgoY8aMkfPnz0tiYqIEBweLXq+XTp06yYIFC6SmpkZERL744guJiYkRk8kkSUlJ8sorr4jZbBYA0rlzZ9m9e7e88cYbYrVaBYCEh4fLhx9+KGvXrnWMFRwcLNnZ2SIismXLFgkKCpIlS5Yo6/zoo48kLi5OADT5+Oijjxyv2b59u4wfP17i4uIkICBA/P39pVu3brJ48WK5detWgzHKy8tl6NCh0qFDBwEgOp1OHnjgAcnIyFDWEhoaKs8//7zjufnz58uePXscfy9cuFAiIiIc0+vRo4fs3r3b5eXT3OXpyzQREQ/k0l2l/k7QvKfjvYHL03XcxSAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiW/23ch4LuLpmqa5ukyqJWkpKR4uoS7Ai8554K9e/fim2++8XQZba7+8va+cPXoqKgoDB482NNleD0GBDmMGzcOAJCbm+vhSshb8BgEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIldGQdYAABlySURBVFJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlP08XQJ7x7bffory83KmtoqICAHDu3DmndovFgtDQULfVRt5DExHxdBHkfmvWrMH06dNd6rt69Wr8+Mc/buOKyBsxIHxUaWkpwsPDYbfbm+xnMBhw5coVBAcHu6ky8iY8BuGjgoODMWrUKPj5qfcy/fz88MQTTzAcfBgDwoelpaWhtrZW+XxtbS3S0tLcWBF5G+5i+LBbt24hJCQENput0edNJhO+/fZbmM1mN1dG3oJbED7MaDTimWeegcFgaPCcwWBAcnIyw8HHMSB83MSJExs9UGm32zFx4kQPVETehLsYPq6mpgYdO3ZEaWmpU3v79u1RXFzc6NYF+Q5uQfg4Pz8/pKamwt/f39FmMBgwceJEhgMxIAiYMGECqqurHX/b7XZMmDDBgxWRt+AuBkFEEBkZicLCQgBAREQECgsLoWmahysjT+MWBEHTNKSlpcHf3x8GgwFTpkxhOBAABgT9U/1uBs9e0L/y6V9zvvXWW9i7d6+ny/Aa7dq1AwAsWbLEw5V4j8GDB+PFF1/0dBke49MBsXfvXuzbtw8JCQmeLsUrxMTEeLoEr7Jv3z5Pl+BxPh0QAJCQkIB169Z5ugyvcPbsWQBAXFychyvxDmPHjvV0CR7n8wFB/4fBQP+OBymJSIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBDNsGzZMnTs2BGapuHdd9/1dDkuqaurQ2ZmJhITE+94Gnl5eYiNjYWmadA0DRERES7dku/w4cNITU1Fly5dEBAQgNDQUPTt29fpgjSpqamO6d7usXnz5ga1/OIXv2iyhrfeeguapkGn0yE+Ph67du264/fBFzEgmmHu3LnYs2ePp8tw2enTpzF06FC8+OKLytvruSI5ORnnzp1DXFwcrFYrioqK8Mc//rHJ1xw9ehSJiYmIiIjAzp07UVZWhj179mDUqFH45JNPnPpu374d169fh91ux+XLlwEAo0ePRnV1NSoqKlBcXIyf/OQnDWoBgNWrVyvvUF5bW4vf/e53AIDhw4ejoKAAQ4cOveP3wRcxINpYZWVli/5736nDhw/j5ZdfxnPPPYd+/fq5ffxly5ahffv2yMrKQufOnWE0GtG1a1f86le/gslkcvTTNA2PPPIIrFar053GNU2DwWCA2WxGWFgYBgwY0GCMAQMGoKioCBs2bGi0hry8PNx///2tP3M+hAHRxtasWYPi4mK3j9u3b1/k5eVh0qRJCAgIcPv4V69eRVlZGa5du+bU7u/vj02bNjn+zs7Odun+nzNmzMBTTz3l1DZr1iwAwDvvvNPoa9566y289NJLzS2d/gUDohXk5+dj0KBBMJvNsFgs6N27N8rLyzFnzhy89NJLOHv2LDRNwwMPPICsrCwEBgZCp9NhwIABCA8Ph8FgQGBgIPr3748hQ4YgKioKRqMR7du3x/z589u09m3btsFisSAjI6NVpztw4EBUVFRg+PDh+PTTT1t12vWGDx+O7t27Y+fOnTh58qTTc59++ilsNhsef/zxNhnbVzAgWqiiogKjR49GSkoKrl27htOnT6Nr166orq5GVlYWfvCDHyAuLg4igjNnzmDOnDmYN28eRATvvPMOvv76axQVFWHo0KE4dOgQXnnlFRw6dAjXrl3D1KlTsXTpUhw+fLjN6q+trQXw3cHM1jR//nw89NBDOHz4MJKSktCzZ0/85je/abBF0VIzZ84EgAYHjZcvX+7TV6NuLQyIFjp//jzKy8vRs2dPGI1GhIeHIy8vD6Ghobd9bY8ePWA2mxESEuK41V10dDRCQ0NhNpsdZwoKCgrarP4nn3wS5eXltz0b0Fwmkwl79uzBb3/7W8THx+P48eNIT09H9+7dkZ+f32rjTJ06FYGBgfjggw9QWVkJADh37hz279/P+3u0AgZEC8XGxqJjx45IS0vD4sWLcf78+TuaTv3Nc2tqahxt9TfPVR2l93YGgwGzZ8/GiRMnsG/fPjz99NMoLi7G2LFjG9xN/E5ZrVZMnDgRpaWlWLt2LQAgMzMTs2bNcrohMd0ZBkQLmUwm7NixA0lJScjIyEBsbCxSU1Md/83oOw8//DD+9Kc/4bnnnkNJSQl27tzZatOuP1j57rvv4vr161i3bp1j14NahgHRCnr27IlNmzahsLAQ6enpyMnJwbJlyzxdllvt2rULmZmZjr+Tk5OdtobqTZ48GQBa9L2Mf9evXz8kJCTg888/x4wZMzB27FgEBwe32vR9GQOihQoLC3H8+HEAQFhYGF5//XX079/f0eYrDh48iMDAQMffVVVVjb4H9Wcb+vTp06rj129FrF+/Hj//+c9bddq+jAHRQoWFhZg5cyYKCgpQXV2NQ4cO4cKFC47b+XXo0AGFhYU4f/48bty44XXHE7Zu3dqi05x2ux1XrlzBJ5984hQQAPDMM88gNzcX169fR1lZGTZu3IiXX34ZP/zhD1s9IMaNG4fQ0FA888wziI2NbdVp+zTxYSkpKZKSkuJy/+XLl0t4eLgAkMDAQBkzZoycP39eEhMTJTg4WPR6vXTq1EkWLFggNTU1IiLyxRdfSExMjJhMJklKSpJXXnlFzGazAJDOnTvL7t275Y033hCr1SoAJDw8XD788ENZu3atY6zg4GDJzs5u1rzt3btXHnnkEbnvvvsEgACQiIgISUxMlPz8fEe/LVu2SFBQkCxZskQ5rY8++kji4uIc01E9PvroI8drtm/fLuPHj5e4uDgJCAgQf39/6datmyxevFhu3brVYIzy8nIZOnSodOjQQQCITqeTBx54QDIyMpS1hIaGyvPPP+94bv78+bJnzx7H3wsXLpSIiAjH9Hr06CG7d+92+T1s7vpxL9JERNyeSl6i/t6LvDcnNYbrB3cxiKgJDIi7REFBgUs/iU5NTfV0qXQP4d297xLx8fHw4b1B8hBuQRCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIyed/7r1v3z7HlYOI/tW+ffsc1xb1VT4dEIMHD/Z0CV7lwIEDAICHHnrIw5V4h4SEBJ9fR3z6mpTkbNy4cQCA3NxcD1dC3oLHIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEhJExHxdBHkfn/4wx+QlZWF2tpaR1tJSQkAICwszNGm1+sxZ84cTJs2zd0lkhdgQPiokydPIj4+3qW+J06ccLkv3Vu4i+GjunXrht69e0PTNGUfTdPQu3dvhoMPY0D4sClTpkCv1yuf9/Pzw9SpU91YEXkb7mL4sMLCQkRGRkK1CmiahosXLyIyMtLNlZG34BaED+vUqRMSExOh0zVcDXQ6HRITExkOPo4B4eMmT57c6HEITdMwZcoUD1RE3oS7GD7u2rVrCA8PR01NjVO7Xq/HlStXEBIS4qHKyBtwC8LHdejQASNHjoSfn5+jTa/XY+TIkQwHYkAQkJaWhrq6OsffIoLJkyd7sCLyFtzFIFRUVCA0NBS3bt0CAAQEBODbb79Fu3btPFwZeRq3IAiBgYEYPXo0DAYD/Pz88PTTTzMcCAADgv5p0qRJqKmpQW1tLSZOnOjpcshL+N2+i2/Kzc31dAluVVtbC6PRCBHBzZs3fW7+x40b5+kSvBKPQSg09RsFuvfwY9A47mI0IScnByLiM48dO3Zg586dHq/DnY+cnBxPr2ZejbsY5PDoo496ugTyMgwIcmjsNxnk27hGEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBkQbmT59OoKCgqBpGr788ktPl9NseXl5iI2NhaZpTg9/f3907NgRw4YNw9KlS1FaWurpUqkNMSDayOrVq/Hee+95uow7lpycjHPnziEuLg5WqxUigrq6OhQXFyM3NxddunRBeno6evbsiQMHDni6XGojDAhymaZpaN++PYYNG4b3338fubm5uHLlCp588kmUlZV5ujxqAwyINnSvX7YuJSUF06ZNQ3FxMd59911Pl0NtgAHRSkQES5cuRbdu3RAQEACr1Yp58+Y16FdbW4tFixYhOjoaJpMJffr0cVz2bOXKlQgMDITZbMbGjRvxxBNPwGKxIDIyEtnZ2U7Tyc/Px6BBg2A2m2GxWNC7d2+Ul5ffdgwA2LZtGywWCzIyMlo839OmTQMAbN261avmkVqJUKMASE5Ojsv9FyxYIJqmyfLly6W0tFRsNpusWLFCAMihQ4cc/ebOnSsBAQGyfv16KS0tlVdffVV0Op3s37/fMR0A8vHHH0tZWZkUFxfLkCFDJDAwUKqrq0VE5ObNm2KxWOTNN9+UyspKKSoqkjFjxkhJSYlLY2zevFmCgoLktddeu+18xcXFidVqVT5fXl4uACQqKsqr5tFVOTk5wo+BGt8ZheYEhM1mE7PZLCNHjnRqz87OdgqIyspKMZvNkpqa6vTagIAAmTVrloj834ensrLS0ac+aM6cOSMiIl999ZUAkM2bNzeoxZUxmuN2ASEiommatG/f/q6cRwZE07iL0QrOnDkDm82GESNGNNnv5MmTsNls6NWrl6PNZDIhIiICBQUFytf5+/sDAOx2OwAgNjYWHTt2RFpaGhYvXozz58+3eIw7VVFRARGBxWJp0fjePI++jAHRCi5dugQACAsLa7JfRUUFAGDhwoVO3y24cOECbDaby+OZTCbs2LEDSUlJyMjIQGxsLFJTU1FZWdlqY7jq1KlTAID4+HgA9+Y8+jIGRCswGo0AgKqqqib71QdIZmZmg/sz7N27t1lj9uzZE5s2bUJhYSHS09ORk5ODZcuWteoYrti2bRsA4IknngBwb86jL2NAtIJevXpBp9MhPz+/yX5RUVEwGo0t/mZlYWEhjh8/DuC7D+Trr7+O/v374/jx4602hiuKioqQmZmJyMhI/OhHPwJw782jr2NAtIKwsDAkJydj/fr1WLNmDcrLy3HkyBGsWrXKqZ/RaMSzzz6L7OxsrFy5EuXl5aitrcWlS5dw+fJll8crLCzEzJkzUVBQgOrqahw6dAgXLlxAQkKCS2Ns3bq1Wac5Rb67X2ddXR1EBCUlJcjJycEjjzwCvV6PDRs2OI5BeMs8Uitx80HRuwaaeZrzxo0bMn36dAkJCZF27dpJUlKSLFq0SABIZGSkHD58WEREqqqqJD09XaKjo8XPz0/CwsIkOTlZjh07JitWrBCz2SwA5MEHH5SzZ8/KqlWrxGKxCACJiYmRU6dOyfnz5yUxMVGCg4NFr9dLp06dZMGCBVJTU3PbMUREtmzZIkFBQbJkyRLl/Pz5z3+WPn36iNlsFn9/f9HpdALAccZi0KBB8tprr8nVq1cbvNYb5tFVPIvRNN68V0HTNOTk5PCuz/e43NxcjB8/HvwYNI67GESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpOTn6QK8Ga+QfO/jMm4aLzmncK/feJec8WPQOG5BKPjiClN//c3c3FwPV0LegscgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISMnP0wWQZ+Tn52Pfvn1ObQUFBQCAN99806k9ISEBjz76qNtqI++hiYh4ughyv7/+9a94/PHHYTAYoNM1viFZV1cHu92O7du3Y+TIkW6ukLwBA8JH1dbWIjw8HFevXm2yX3BwMIqLi+Hnx41NX8RjED5Kr9dj0qRJ8Pf3V/bx9/fH5MmTGQ4+jAHhwyZMmIDq6mrl89XV1ZgwYYIbKyJvw10MHxcTE4OLFy82+lxkZCQuXrwITdPcXBV5C25B+Li0tDQYDIYG7f7+/pg6dSrDwcdxC8LHnThxAj169Gj0uaNHj6JXr15uroi8CQOC0KNHD5w4ccKpLT4+vkEb+R7uYhCmTJnitJthMBgwdepUD1ZE3oJbEISLFy+ic+fOqF8VNE3DuXPn0LlzZ88WRh7HLQhCdHQ0HnroIeh0OmiahoEDBzIcCAADgv5pypQp0Ol00Ov1mDx5sqfLIS/BXQwCAJSUlOC+++4DAPzjH/9AeHi4hysib+BzAcHz+tQSPvZx8c2fe8+ZMweDBw/2dBleJz8/H5qmYejQoZ4uxevs3bsXWVlZni7D7XwyIAYPHoxx48Z5ugyvM2rUKACAxWLxcCXeiQFBPo3BQP+OZzGISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBDNNH36dAQFBUHTNHz55ZeeLqdF6urqkJmZicTExDueRl5eHmJjY6FpmtPD398fHTt2xLBhw7B06VKUlpa2YuXkLgyIZlq9ejXee+89T5fRYqdPn8bQoUPx4osvwmaz3fF0kpOTce7cOcTFxcFqtUJEUFdXh+LiYuTm5qJLly5IT09Hz549ceDAgVacA3IHBoQPOnz4MF5++WU899xz6NevX6tPX9M0tG/fHsOGDcP777+P3NxcXLlyBU8++STKyspafTxqOwyIO3C3X9eyb9++yMvLw6RJkxAQENDm46WkpGDatGkoLi7Gu+++2+bjUethQNyGiGDp0qXo1q0bAgICYLVaMW/evAb9amtrsWjRIkRHR8NkMqFPnz7IyckBAKxcuRKBgYEwm83YuHEjnnjiCVgsFkRGRiI7O9tpOvn5+Rg0aBDMZjMsFgt69+6N8vLy247RFrZt2waLxYKMjIwWT2vatGkAgK1btzra7sX37J4jPgaA5OTkuNx/wYIFommaLF++XEpLS8Vms8mKFSsEgBw6dMjRb+7cuRIQECDr16+X0tJSefXVV0Wn08n+/fsd0wEgH3/8sZSVlUlxcbEMGTJEAgMDpbq6WkREbt68KRaLRd58802prKyUoqIiGTNmjJSUlLg0xp14+OGHpW/fvo0+t3nzZgkKCpLXXnvtttOJi4sTq9WqfL68vFwASFRUlKPtbnrPcnJyxAc/LuJzc9ycgLDZbGI2m2XkyJFO7dnZ2U4BUVlZKWazWVJTU51eGxAQILNmzRKR/1vZKysrHX3qg+bMmTMiIvLVV18JANm8eXODWlwZ4040FRDNcbuAEBHRNE3at28vInffe+arAcFdjCacOXMGNpsNI0aMaLLfyZMnYbPZ0KtXL0ebyWRCREQECgoKlK/z9/cHANjtdgBAbGwsOnbsiLS0NCxevBjnz59v8RjeoqKiAiLiuDAu37O7AwOiCZcuXQIAhIWFNdmvoqICALBw4UKn7wJcuHChWacQTSYTduzYgaSkJGRkZCA2NhapqamorKxstTE85dSpUwCA+Ph4AHzP7hYMiCYYjUYAQFVVVZP96gMkMzMT8t1um+Oxd+/eZo3Zs2dPbNq0CYWFhUhPT0dOTg6WLVvWqmN4wrZt2wAATzzxBAC+Z3cLBkQTevXqBZ1Oh/z8/Cb7RUVFwWg0tviblYWFhTh+/DiA7z5Ar7/+Ovr374/jx4+32hieUFRUhMzMTERGRuJHP/oRAL5ndwsGRBPCwsKQnJyM9evXY82aNSgvL8eRI0ewatUqp35GoxHPPvsssrOzsXLlSpSXl6O2thaXLl3C5cuXXR6vsLAQM2fOREFBAaqrq3Ho0CFcuHABCQkJrTZGc2zdurVZpzlFBDdv3kRdXR1EBCUlJcjJycEjjzwCvV6PDRs2OI5B3Kvv2T3HzQdFPQ7NPM1548YNmT59uoSEhEi7du0kKSlJFi1aJAAkMjJSDh8+LCIiVVVVkp6eLtHR0eLn5ydhYWGSnJwsx44dkxUrVojZbBYA8uCDD8rZs2dl1apVYrFYBIDExMTIqVOn5Pz585KYmCjBwcGi1+ulU6dOsmDBAqmpqbntGM2xd+9eeeSRR+S+++4TAAJAIiIiJDExUfLz8x39tmzZIkFBQbJkyRLltP785z9Lnz59xGw2i7+/v+h0OgHgOGMxaNAgee211+Tq1asNXns3vWe+ehbDJ+/unZOTw3tzUrPk5uZi/PjxPnd3b+5iEJESA+IeUFBQ0ODn1o09UlNTPV0q3WV4d+97QHx8vM9t+pJ7cAuCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREo+eUUpojvlYx8X37seBO/LSOQ6n9uCICLX8RgEESkxIIhIiQFBREp+ANZ5uggi8k7/HyKTmiLMuyVaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epHEjB6hHudl"
      },
      "source": [
        "Building our Neural Network model\n",
        "\n",
        "This includes training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLsARKih95Ky",
        "outputId": "cf6c64d1-7db1-45d1-de01-8b682307d95a"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# modelcheckpoint is used to save our model and weights at some interval.\n",
        "\n",
        "checkpoint_path = F\"/content/drive/My Drive/Neural_Network/next_word.h5\"\n",
        "\n",
        "# passing file path to save our model. we will monitor total loss valu.\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor = 'loss', verbose = 1, save_best_only = True)\n",
        "\n",
        "# compiling our model by passing the loss and optimizer function.\n",
        "# categorical_crossentropy is used to multi-class classification (several possible outputs and the model has to choose one).\n",
        "# Adam optimizer is passed to update the weights iteratively based on training data.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001))\n",
        "\n",
        "# Fitting the model by passing the independent and dependent variables.\n",
        "# Epochs is the number of iterations to be performed.\n",
        "# batch_size is the number of training samples in one forward or backward pass. Higher batch size require more memory space.\n",
        "model.fit(x, y, epochs = 70, batch_size=64, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "1739/1739 [==============================] - 49s 24ms/step - loss: 6.4486\n",
            "\n",
            "Epoch 00001: loss improved from inf to 6.44862, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 2/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 5.8219\n",
            "\n",
            "Epoch 00002: loss improved from 6.44862 to 5.82192, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 3/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 5.4538\n",
            "\n",
            "Epoch 00003: loss improved from 5.82192 to 5.45379, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 4/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 5.1772\n",
            "\n",
            "Epoch 00004: loss improved from 5.45379 to 5.17717, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 5/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 4.9263\n",
            "\n",
            "Epoch 00005: loss improved from 5.17717 to 4.92633, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 6/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 4.6851\n",
            "\n",
            "Epoch 00006: loss improved from 4.92633 to 4.68508, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 7/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 4.4417\n",
            "\n",
            "Epoch 00007: loss improved from 4.68508 to 4.44174, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 8/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 4.1881\n",
            "\n",
            "Epoch 00008: loss improved from 4.44174 to 4.18805, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 9/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 3.9204\n",
            "\n",
            "Epoch 00009: loss improved from 4.18805 to 3.92037, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 10/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 3.6351\n",
            "\n",
            "Epoch 00010: loss improved from 3.92037 to 3.63507, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 11/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 3.3330\n",
            "\n",
            "Epoch 00011: loss improved from 3.63507 to 3.33301, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 12/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 3.0167\n",
            "\n",
            "Epoch 00012: loss improved from 3.33301 to 3.01668, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 13/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 2.6777\n",
            "\n",
            "Epoch 00013: loss improved from 3.01668 to 2.67775, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 14/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 2.3171\n",
            "\n",
            "Epoch 00014: loss improved from 2.67775 to 2.31712, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 15/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 1.9467\n",
            "\n",
            "Epoch 00015: loss improved from 2.31712 to 1.94674, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 16/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 1.5922\n",
            "\n",
            "Epoch 00016: loss improved from 1.94674 to 1.59219, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 17/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 1.2717\n",
            "\n",
            "Epoch 00017: loss improved from 1.59219 to 1.27174, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 18/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 1.0052\n",
            "\n",
            "Epoch 00018: loss improved from 1.27174 to 1.00515, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 19/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.7906\n",
            "\n",
            "Epoch 00019: loss improved from 1.00515 to 0.79055, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 20/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.6306\n",
            "\n",
            "Epoch 00020: loss improved from 0.79055 to 0.63058, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 21/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.5265\n",
            "\n",
            "Epoch 00021: loss improved from 0.63058 to 0.52647, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 22/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.4459\n",
            "\n",
            "Epoch 00022: loss improved from 0.52647 to 0.44589, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 23/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.3958\n",
            "\n",
            "Epoch 00023: loss improved from 0.44589 to 0.39580, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 24/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.3497\n",
            "\n",
            "Epoch 00024: loss improved from 0.39580 to 0.34965, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 25/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.3280\n",
            "\n",
            "Epoch 00025: loss improved from 0.34965 to 0.32802, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 26/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2990\n",
            "\n",
            "Epoch 00026: loss improved from 0.32802 to 0.29905, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 27/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2842\n",
            "\n",
            "Epoch 00027: loss improved from 0.29905 to 0.28424, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 28/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2681\n",
            "\n",
            "Epoch 00028: loss improved from 0.28424 to 0.26811, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 29/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2614\n",
            "\n",
            "Epoch 00029: loss improved from 0.26811 to 0.26137, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 30/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2412\n",
            "\n",
            "Epoch 00030: loss improved from 0.26137 to 0.24116, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 31/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2343\n",
            "\n",
            "Epoch 00031: loss improved from 0.24116 to 0.23431, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 32/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2298\n",
            "\n",
            "Epoch 00032: loss improved from 0.23431 to 0.22980, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 33/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2170\n",
            "\n",
            "Epoch 00033: loss improved from 0.22980 to 0.21701, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 34/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.2130\n",
            "\n",
            "Epoch 00034: loss improved from 0.21701 to 0.21302, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 35/70\n",
            "1739/1739 [==============================] - 41s 24ms/step - loss: 0.2106\n",
            "\n",
            "Epoch 00035: loss improved from 0.21302 to 0.21064, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 36/70\n",
            "1739/1739 [==============================] - 41s 24ms/step - loss: 0.1963\n",
            "\n",
            "Epoch 00036: loss improved from 0.21064 to 0.19630, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 37/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1963\n",
            "\n",
            "Epoch 00037: loss improved from 0.19630 to 0.19628, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 38/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1877\n",
            "\n",
            "Epoch 00038: loss improved from 0.19628 to 0.18770, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 39/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1889\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.18770\n",
            "Epoch 40/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1836\n",
            "\n",
            "Epoch 00040: loss improved from 0.18770 to 0.18365, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 41/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1761\n",
            "\n",
            "Epoch 00041: loss improved from 0.18365 to 0.17608, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 42/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1759\n",
            "\n",
            "Epoch 00042: loss improved from 0.17608 to 0.17591, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 43/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1711\n",
            "\n",
            "Epoch 00043: loss improved from 0.17591 to 0.17114, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 44/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1685\n",
            "\n",
            "Epoch 00044: loss improved from 0.17114 to 0.16848, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 45/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1611\n",
            "\n",
            "Epoch 00045: loss improved from 0.16848 to 0.16111, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 46/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1614\n",
            "\n",
            "Epoch 00046: loss did not improve from 0.16111\n",
            "Epoch 47/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1616\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.16111\n",
            "Epoch 48/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1568\n",
            "\n",
            "Epoch 00048: loss improved from 0.16111 to 0.15678, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 49/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1536\n",
            "\n",
            "Epoch 00049: loss improved from 0.15678 to 0.15365, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 50/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1521\n",
            "\n",
            "Epoch 00050: loss improved from 0.15365 to 0.15209, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 51/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1494\n",
            "\n",
            "Epoch 00051: loss improved from 0.15209 to 0.14944, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 52/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1460\n",
            "\n",
            "Epoch 00052: loss improved from 0.14944 to 0.14601, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 53/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1450\n",
            "\n",
            "Epoch 00053: loss improved from 0.14601 to 0.14503, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 54/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1421\n",
            "\n",
            "Epoch 00054: loss improved from 0.14503 to 0.14209, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 55/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1418\n",
            "\n",
            "Epoch 00055: loss improved from 0.14209 to 0.14181, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 56/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1384\n",
            "\n",
            "Epoch 00056: loss improved from 0.14181 to 0.13837, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 57/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1380\n",
            "\n",
            "Epoch 00057: loss improved from 0.13837 to 0.13799, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 58/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1356\n",
            "\n",
            "Epoch 00058: loss improved from 0.13799 to 0.13560, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 59/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1392\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.13560\n",
            "Epoch 60/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1392\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.13560\n",
            "Epoch 61/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1319\n",
            "\n",
            "Epoch 00061: loss improved from 0.13560 to 0.13188, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 62/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1295\n",
            "\n",
            "Epoch 00062: loss improved from 0.13188 to 0.12952, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 63/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1374\n",
            "\n",
            "Epoch 00063: loss did not improve from 0.12952\n",
            "Epoch 64/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1230\n",
            "\n",
            "Epoch 00064: loss improved from 0.12952 to 0.12297, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n",
            "Epoch 65/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1262\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.12297\n",
            "Epoch 66/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1295\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.12297\n",
            "Epoch 67/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1230\n",
            "\n",
            "Epoch 00067: loss did not improve from 0.12297\n",
            "Epoch 68/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1245\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.12297\n",
            "Epoch 69/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1230\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.12297\n",
            "Epoch 70/70\n",
            "1739/1739 [==============================] - 42s 24ms/step - loss: 0.1212\n",
            "\n",
            "Epoch 00070: loss improved from 0.12297 to 0.12115, saving model to /content/drive/My Drive/Neural_Network/next_word.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fea85422910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxFSgVDFKrP3"
      },
      "source": [
        "checkpoint_path = F\"/content/drive/My Drive/Neural_Network/next_word.h5\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDfseUDZgL67"
      },
      "source": [
        "Prediction from our Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a65JV9ki95IM"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Loading the model file.\n",
        "model = load_model(checkpoint_path) \n",
        "\n",
        "# Loading the tokenizer file.\n",
        "tokenizer = pickle.load(open(F\"/content/drive/My Drive/Neural_Network/token.pkl\", 'rb'))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIHcWzq095FZ"
      },
      "source": [
        "def predict_next_word(model, tokenizer, text):\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  predt = np.argmax(model.predict(sequence))\n",
        "  predicted_word = ''\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "    if value ==predt:\n",
        "      predicted_word = key\n",
        "      break\n",
        "  \n",
        "  print('Prediction of the model =======>  ', predicted_word)\n",
        "  return predicted_word\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maxHDls9guRf"
      },
      "source": [
        "Taking input from the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjgDHzLW95Cc",
        "outputId": "1269b68a-b2b7-4e72-81dc-e823386c9752"
      },
      "source": [
        "while(True):\n",
        "  text = input('Enter the text : ')\n",
        "\n",
        "  if text == '0':\n",
        "    print('Execution completed!')\n",
        "    break\n",
        "  else:\n",
        "    try:\n",
        "      text = text.split(' ')\n",
        "      text = text[-4:]\n",
        "      print(text)\n",
        "\n",
        "      predict_next_word(model, tokenizer, text)\n",
        "    except Exception as e:\n",
        "      print('Error occured : ', e)\n",
        "      continue"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text : But for the trained reasoner to admit such intrusions into his own\n",
            "['intrusions', 'into', 'his', 'own']\n",
            "Prediction of the model =======>   delicate\n",
            "Enter the text : were sufficient to absorb all my\n",
            "['to', 'absorb', 'all', 'my']\n",
            "Prediction of the model =======>   attention\n",
            "Enter the text : faculties and extraordinary powers of\n",
            "['and', 'extraordinary', 'powers', 'of']\n",
            "Prediction of the model =======>   observation\n",
            "Enter the text : By the way, since you are interested in these little\n",
            "['interested', 'in', 'these', 'little']\n",
            "Prediction of the model =======>   problems\n",
            "Enter the text : 0\n",
            "Execution completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys81rQkSEAgS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}